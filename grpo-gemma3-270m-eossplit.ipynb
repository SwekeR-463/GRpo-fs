{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets -q\n!pip install peft -q\n!pip install accelerate -q\n!pip install transformers -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T03:59:20.400816Z","iopub.execute_input":"2025-08-15T03:59:20.401288Z","iopub.status.idle":"2025-08-15T04:00:53.957761Z","shell.execute_reply.started":"2025-08-15T03:59:20.401259Z","shell.execute_reply":"2025-08-15T04:00:53.956774Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T04:59:19.283881Z","iopub.execute_input":"2025-08-15T04:59:19.284703Z","iopub.status.idle":"2025-08-15T04:59:19.747479Z","shell.execute_reply.started":"2025-08-15T04:59:19.284680Z","shell.execute_reply":"2025-08-15T04:59:19.746639Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"645f2caa6f6d4ed980fc165999b56d09"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import os\nos.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"  # <- hard off switch\n# (alias works too in some builds)\nos.environ[\"TORCH_COMPILE_DISABLE\"] = \"1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T04:53:49.679030Z","iopub.execute_input":"2025-08-15T04:53:49.679201Z","iopub.status.idle":"2025-08-15T04:53:49.686490Z","shell.execute_reply.started":"2025-08-15T04:53:49.679186Z","shell.execute_reply":"2025-08-15T04:53:49.685803Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import re\nimport time\nimport gc\nimport ctypes\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom peft import (\n    get_peft_config, \n    get_peft_model, \n    LoraConfig,\n    TaskType,\n)\n\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.amp import autocast, GradScaler\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom sklearn.utils import shuffle\nfrom transformers import get_cosine_schedule_with_warmup","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T04:59:34.298742Z","iopub.execute_input":"2025-08-15T04:59:34.299089Z","iopub.status.idle":"2025-08-15T05:00:11.742197Z","shell.execute_reply.started":"2025-08-15T04:59:34.299062Z","shell.execute_reply":"2025-08-15T05:00:11.741376Z"}},"outputs":[{"name":"stderr","text":"2025-08-15 04:59:54.885948: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755233995.254214      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755233995.356661      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Reward Functions","metadata":{}},{"cell_type":"markdown","source":"This is accuracy reward which is rewarded for correct output.","metadata":{}},{"cell_type":"code","source":"def accuracy_reward(prompt_completions, answer):\n    rewards = []\n    for pc in prompt_completions:\n        completion = pc.split('<answer>')[-1]\n        if answer in completion and (pc.count('<answer>') == 2):\n            rewards.append(2.0)\n        else:\n            rewards.append(0.0)\n    return rewards","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:11.743450Z","iopub.execute_input":"2025-08-15T05:00:11.744044Z","iopub.status.idle":"2025-08-15T05:00:11.748440Z","shell.execute_reply.started":"2025-08-15T05:00:11.744022Z","shell.execute_reply":"2025-08-15T05:00:11.747806Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"This rewards for maintaining the format.","metadata":{}},{"cell_type":"code","source":"def format_reward(prompt_completions):\n    completions = []\n    for pc in prompt_completions:\n        completion = pc.split('\\nAssistant:')[-1]\n        count_eos_string = completion.count(tokenizer.eos_token)\n        if count_eos_string <= 1:\n            completion = completion\n        else:\n            completion = completion.replace(tokenizer.eos_token, '')\n            completion = completion + tokenizer.eos_token\n        completions.append(completion)\n    rewards = []\n    pattern = re.compile(r\".*<reasoning>\\n.+?\\n</reasoning>\\n<answer>\\n.+?\\n</answer>\", re.DOTALL)\n    for completion in completions:\n        rewards.append(0.5 if pattern.fullmatch(completion) else 0.0)\n    return rewards","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:11.749297Z","iopub.execute_input":"2025-08-15T05:00:11.749591Z","iopub.status.idle":"2025-08-15T05:00:11.769871Z","shell.execute_reply.started":"2025-08-15T05:00:11.749564Z","shell.execute_reply":"2025-08-15T05:00:11.769269Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Load and Process Data","metadata":{}},{"cell_type":"code","source":"import datasets\n\ndata = datasets.load_dataset('openai/gsm8k', 'main')\n\ndf_train = data['train'].to_pandas()\ndf_test = data['test'].to_pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:11.771209Z","iopub.execute_input":"2025-08-15T05:00:11.771435Z","iopub.status.idle":"2025-08-15T05:00:17.090007Z","shell.execute_reply.started":"2025-08-15T05:00:11.771416Z","shell.execute_reply":"2025-08-15T05:00:17.089156Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e7e7fb45ccc4d9e91c0667cf0170c43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"main/train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5720032450c542e2a0044064796ce8b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"main/test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b9c6dd94cb840f4821f90d636f03ced"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5c15a001de74cc2bc026cdb272cbc4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc2407f2c9254c9b826aa39ff9d754c9"}},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"### Extract Answer","metadata":{}},{"cell_type":"code","source":"df_train['answer'] = df_train['answer'].str.split('####').str[-1].str.strip()\ndf_test['answer'] = df_test['answer'].str.split('####').str[-1].str.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:17.090887Z","iopub.execute_input":"2025-08-15T05:00:17.091527Z","iopub.status.idle":"2025-08-15T05:00:17.125920Z","shell.execute_reply.started":"2025-08-15T05:00:17.091505Z","shell.execute_reply":"2025-08-15T05:00:17.124794Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Create and Apply Chat Template","metadata":{}},{"cell_type":"code","source":"SYSTEM = \"\"\"\nRespond in the following format:\n<reasoning>\n...\n</reasoning>\n<answer>\n...\n</answer>\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:17.126949Z","iopub.execute_input":"2025-08-15T05:00:17.127266Z","iopub.status.idle":"2025-08-15T05:00:17.142872Z","shell.execute_reply.started":"2025-08-15T05:00:17.127231Z","shell.execute_reply":"2025-08-15T05:00:17.142303Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df_train['prompt'] = SYSTEM + 'User: ' + df_train['question'].str.strip() + '\\nAssistant:'\ndf_test['prompt'] = SYSTEM + 'User: ' + df_test['question'].str.strip() + '\\nAssistant:'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:17.143668Z","iopub.execute_input":"2025-08-15T05:00:17.143881Z","iopub.status.idle":"2025-08-15T05:00:17.173747Z","shell.execute_reply.started":"2025-08-15T05:00:17.143863Z","shell.execute_reply":"2025-08-15T05:00:17.173102Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"print(df_train.prompt[69])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:17.174616Z","iopub.execute_input":"2025-08-15T05:00:17.174841Z","iopub.status.idle":"2025-08-15T05:00:17.190757Z","shell.execute_reply.started":"2025-08-15T05:00:17.174823Z","shell.execute_reply":"2025-08-15T05:00:17.190002Z"}},"outputs":[{"name":"stdout","text":"\nRespond in the following format:\n<reasoning>\n...\n</reasoning>\n<answer>\n...\n</answer>\nUser: Carly collected 7 starfish with 5 arms each and one seastar with 14 arms. How many arms do the animals she collected have in total?\nAssistant:\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"model_path = 'google/gemma-3-270m' \ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:17.191469Z","iopub.execute_input":"2025-08-15T05:00:17.191663Z","iopub.status.idle":"2025-08-15T05:00:17.208719Z","shell.execute_reply.started":"2025-08-15T05:00:17.191648Z","shell.execute_reply":"2025-08-15T05:00:17.207900Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    device_map=device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:17.211877Z","iopub.execute_input":"2025-08-15T05:00:17.212137Z","iopub.status.idle":"2025-08-15T05:00:21.696611Z","shell.execute_reply.started":"2025-08-15T05:00:17.212113Z","shell.execute_reply":"2025-08-15T05:00:21.695922Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c62c4a2321774f5eb3f10a30508165aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/536M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10e44bdb8bc94c518d6e8d0ad34b4c86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5869d493e4804314b661d32d4dc70ba9"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"peft_config = LoraConfig(\n        task_type=TaskType.CAUSAL_LM,\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"up_proj\", \"down_proj\", \"gate_proj\"],\n        bias='none',\n        inference_mode=False,\n        r=8,\n        lora_alpha=16,\n        lora_dropout=0.0\n    )\n\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:21.697494Z","iopub.execute_input":"2025-08-15T05:00:21.697688Z","iopub.status.idle":"2025-08-15T05:00:21.867624Z","shell.execute_reply.started":"2025-08-15T05:00:21.697673Z","shell.execute_reply":"2025-08-15T05:00:21.866731Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"ref_model = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    device_map=device\n).eval().requires_grad_(False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:21.868486Z","iopub.execute_input":"2025-08-15T05:00:21.868676Z","iopub.status.idle":"2025-08-15T05:00:22.666455Z","shell.execute_reply.started":"2025-08-15T05:00:21.868662Z","shell.execute_reply":"2025-08-15T05:00:22.665606Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_path)\ntokenizer.pad_token_id = tokenizer.eos_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:22.667335Z","iopub.execute_input":"2025-08-15T05:00:22.667603Z","iopub.status.idle":"2025-08-15T05:00:26.590479Z","shell.execute_reply.started":"2025-08-15T05:00:22.667584Z","shell.execute_reply":"2025-08-15T05:00:26.589681Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a0f19321491455bb9822528387c7dd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5125b9c63b64c13ab9576dce00d397f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ff60bc3daed4e8592c8a47fb6c21140"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e126b9ff899d4e4d8460ba473d5af566"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43473e6b3a1c4fbfa9b013e254b77ba7"}},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"## Completion Generation Function","metadata":{}},{"cell_type":"code","source":"model.generate = torch._dynamo.disable()(model.generate)\n\ndef generate_completions(model, tokenizer, prompts, temperature=0.9, num_completions=2, max_completion_length=50):\n    \n    model.eval() \n    \n    completions = []\n    for prompt in tqdm(prompts):\n\n        encodings = tokenizer(prompt, return_tensors='pt').to(model.device)\n        \n        # Generate completions using the current policy\n        with torch.inference_mode():\n            outs = model.generate(\n                **encodings, \n                do_sample=True, \n                temperature=temperature, \n                max_new_tokens=max_completion_length,  # Limiting the number of tokens generated\n                num_return_sequences=num_completions,  # Number of generations per prompt\n                pad_token_id=tokenizer.eos_token_id\n            )\n        \n        decoded_texts = tokenizer.batch_decode(outs, skip_special_tokens=False)\n        completions.extend(decoded_texts)\n        \n    model.train()\n    \n    return completions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:26.591261Z","iopub.execute_input":"2025-08-15T05:00:26.591486Z","iopub.status.idle":"2025-08-15T05:00:26.597382Z","shell.execute_reply.started":"2025-08-15T05:00:26.591468Z","shell.execute_reply":"2025-08-15T05:00:26.596594Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Get Log Probs Function","metadata":{}},{"cell_type":"code","source":"def get_log_probs(model, prompt, prompt_completions, type):\n    \n    if type == 'new':\n        prompt_ids = tokenizer(prompt)\n        prompt_len = len(prompt_ids)\n        encodings = tokenizer(prompt_completions, return_tensors='pt', padding='longest').to(model.device)\n\n        with autocast(dtype=torch.bfloat16, device_type='cuda'):\n            logits = model(**encodings).logits\n\n    else:\n        with torch.no_grad():\n            prompt_ids = tokenizer(prompt)\n            prompt_len = len(prompt_ids)\n            encodings = tokenizer(prompt_completions, return_tensors='pt', padding='longest').to(model.device)\n    \n            with autocast(dtype=torch.bfloat16, device_type='cuda'):\n                logits = model(**encodings).logits\n        \n    start = len(tokenizer(prompt).input_ids) \n\n    all_log_probs = []\n    for l, input_ids in zip(logits, encodings.input_ids):\n        eos_pos = torch.where(input_ids == tokenizer.eos_token_id)[0]\n\n        if eos_pos.numel() == 0:\n            completion_logits = l[start-1:-1]\n            completion_ids = input_ids[start:] \n        else:\n            end = eos_pos[0].item() \n            completion_logits = l[start-1:end]\n            completion_ids = input_ids[start:end+1]\n\n        probs = F.softmax(completion_logits, dim=-1)\n        log_probs = torch.log(probs)\n        log_probs = torch.gather(log_probs, 1, completion_ids.unsqueeze(1)).squeeze(1)\n        all_log_probs.append(log_probs)\n\n    return all_log_probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:26.598294Z","iopub.execute_input":"2025-08-15T05:00:26.598669Z","iopub.status.idle":"2025-08-15T05:00:28.738741Z","shell.execute_reply.started":"2025-08-15T05:00:26.598645Z","shell.execute_reply":"2025-08-15T05:00:28.737872Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def check(t):\n    print('ISNAN', torch.isnan(t).any())\n    print('ISINF', torch.isinf(t).any())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:28.739713Z","iopub.execute_input":"2025-08-15T05:00:28.739948Z","iopub.status.idle":"2025-08-15T05:00:28.759625Z","shell.execute_reply.started":"2025-08-15T05:00:28.739929Z","shell.execute_reply":"2025-08-15T05:00:28.758898Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## Hyperparameters","metadata":{}},{"cell_type":"code","source":"epochs = 1\nn_iterations = 5\nlearning_rate = 3e-5\nweight_decay = 0.005\nwarmups = 100\n\neps = 0.2\nbeta = 0.005","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:28.760584Z","iopub.execute_input":"2025-08-15T05:00:28.760837Z","iopub.status.idle":"2025-08-15T05:00:28.777852Z","shell.execute_reply.started":"2025-08-15T05:00:28.760809Z","shell.execute_reply":"2025-08-15T05:00:28.777288Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## Training ","metadata":{}},{"cell_type":"code","source":"def clean_memory(deep=True):\n    gc.collect()\n    if deep:\n        ctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n    torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:28.778598Z","iopub.execute_input":"2025-08-15T05:00:28.778851Z","iopub.status.idle":"2025-08-15T05:00:28.797152Z","shell.execute_reply.started":"2025-08-15T05:00:28.778832Z","shell.execute_reply":"2025-08-15T05:00:28.796535Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"prompts, answers = shuffle(df_train.prompt, df_train.answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:28.797916Z","iopub.execute_input":"2025-08-15T05:00:28.798430Z","iopub.status.idle":"2025-08-15T05:00:28.820809Z","shell.execute_reply.started":"2025-08-15T05:00:28.798409Z","shell.execute_reply":"2025-08-15T05:00:28.820134Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\nscheduler = get_cosine_schedule_with_warmup(optimizer=optimizer, \n                                            num_training_steps=epochs*len(prompts)*n_iterations,\n                                            num_warmup_steps=warmups)\n\nscaler = GradScaler()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:28.821775Z","iopub.execute_input":"2025-08-15T05:00:28.822076Z","iopub.status.idle":"2025-08-15T05:00:28.838455Z","shell.execute_reply.started":"2025-08-15T05:00:28.822056Z","shell.execute_reply":"2025-08-15T05:00:28.837671Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"start_time = time.time()\nmax_duration = 3 * 60 * 60  \n\n\nreward_tracking = []\ntotal_rewards = []\ntrack_format_rewards = []\ntrack_accuracy_rewards = []\n\nstep = 0\nfor epoch in range(epochs):\n    for idx in range(len(df_train)):\n        step += 1\n\n        if time.time() - start_time > max_duration:\n            print(\"Stopping training: Reached 11-hour limit.\")\n            break\n        \n        prompt = prompts[idx]\n        answer = answers[idx]\n        \n        prompt_completions = generate_completions(\n            model=model,\n            tokenizer=tokenizer,\n            prompts=[prompt],\n            temperature=0.8, \n            num_completions=5,\n            max_completion_length=512)\n\n        accuracy_rewards = accuracy_reward(prompt_completions, answer)\n        format_rewards = format_reward(prompt_completions)\n        rewards = torch.tensor(accuracy_rewards) + torch.tensor(format_rewards)\n        advantages = (rewards - rewards.mean()) / (rewards.std() + 1e-4)\n\n        old_log_probs = get_log_probs(model, prompt, prompt_completions, type='old')\n        ref_log_probs = get_log_probs(ref_model, prompt, prompt_completions, type='ref')\n    \n\n        for i_iter in range(n_iterations):\n            if time.time() - start_time > max_duration:\n                print(\"Stopping training: Reached 3-hour limit.\")\n                break\n            \n            new_log_probs = get_log_probs(model, prompt, prompt_completions, type='new')\n\n            loss = 0\n            for i in range(len(old_log_probs)):\n                ratio = torch.exp(new_log_probs[i] - old_log_probs[i]) \n                clipped_ratio = torch.clamp(ratio, min=1-eps, max=1+eps)\n\n                kl_ratio1 = torch.exp(ref_log_probs[i] - new_log_probs[i]) \n                kl_ratio2 = torch.exp(ref_log_probs[i] - new_log_probs[i]).log()\n                kl = kl_ratio1 - kl_ratio2 - 1\n                \n                loss += (-clipped_ratio * advantages[i] - beta*kl).mean()\n                \n            loss = loss / len(new_log_probs)\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            scheduler.step()\n\n            clean_memory()\n            \n            print(f\"Step: {step} | Iter: {i_iter+1} | Loss\", loss.item())\n\n        track_format_rewards.append(sum(format_rewards) / len(format_rewards))\n        track_accuracy_rewards.append(sum(accuracy_rewards) / len(accuracy_rewards))\n        total_rewards.append(sum(rewards)/len(rewards))\n        \n        if step % 10 == 0:\n            print(\n                f'Step: {step}'\n                f' | Format: {sum(track_format_rewards)/len(track_format_rewards)}'\n                f' | Accuracy: {sum(track_accuracy_rewards)/len(track_accuracy_rewards)}'\n            )\n\n\n            print('Output example:', prompt_completions[0].split('\\nAssistant:')[1].strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T05:00:28.839226Z","iopub.execute_input":"2025-08-15T05:00:28.839460Z","iopub.status.idle":"2025-08-15T06:15:59.029453Z","shell.execute_reply.started":"2025-08-15T05:00:28.839443Z","shell.execute_reply":"2025-08-15T06:15:59.028008Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:30<00:00, 30.55s/it]\nIt is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n","output_type":"stream"},{"name":"stdout","text":"Step: 1 | Iter: 1 | Loss 0.0\nStep: 1 | Iter: 2 | Loss 0.0\nStep: 1 | Iter: 3 | Loss 0.0\nStep: 1 | Iter: 4 | Loss 0.0\nStep: 1 | Iter: 5 | Loss 0.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.39s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 2 | Iter: 1 | Loss 0.0\nStep: 2 | Iter: 2 | Loss 0.0\nStep: 2 | Iter: 3 | Loss 0.0\nStep: 2 | Iter: 4 | Loss 0.0\nStep: 2 | Iter: 5 | Loss 0.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 3 | Iter: 1 | Loss 0.0\nStep: 3 | Iter: 2 | Loss 0.0\nStep: 3 | Iter: 3 | Loss 0.0\nStep: 3 | Iter: 4 | Loss 0.0\nStep: 3 | Iter: 5 | Loss 0.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 4 | Iter: 1 | Loss 0.0\nStep: 4 | Iter: 2 | Loss 0.0\nStep: 4 | Iter: 3 | Loss 0.0\nStep: 4 | Iter: 4 | Loss 0.0\nStep: 4 | Iter: 5 | Loss 0.0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.66s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 5 | Iter: 1 | Loss -0.000782012939453125\nStep: 5 | Iter: 2 | Loss -0.0003910064697265625\nStep: 5 | Iter: 3 | Loss -0.000782012939453125\nStep: 5 | Iter: 4 | Loss -0.000782012939453125\nStep: 5 | Iter: 5 | Loss -0.000782012939453125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.64s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 6 | Iter: 1 | Loss -2.4400651454925537e-07\nStep: 6 | Iter: 2 | Loss -2.5890767574310303e-07\nStep: 6 | Iter: 3 | Loss -2.5890767574310303e-07\nStep: 6 | Iter: 4 | Loss -3.6694109439849854e-07\nStep: 6 | Iter: 5 | Loss -3.371387720108032e-07\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.60s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 7 | Iter: 1 | Loss -3.9301812648773193e-07\nStep: 7 | Iter: 2 | Loss -4.731118679046631e-07\nStep: 7 | Iter: 3 | Loss -6.258487701416016e-07\nStep: 7 | Iter: 4 | Loss -5.364418029785156e-07\nStep: 7 | Iter: 5 | Loss -6.705522537231445e-07\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.62s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 8 | Iter: 1 | Loss -7.748603820800781e-07\nStep: 8 | Iter: 2 | Loss -3.0547380447387695e-06\nStep: 8 | Iter: 3 | Loss -7.152557373046875e-07\nStep: 8 | Iter: 4 | Loss -1.6540288925170898e-06\nStep: 8 | Iter: 5 | Loss -1.8477439880371094e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.66s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 9 | Iter: 1 | Loss -1.2665987014770508e-06\nStep: 9 | Iter: 2 | Loss -1.4901161193847656e-06\nStep: 9 | Iter: 3 | Loss -1.2069940567016602e-06\nStep: 9 | Iter: 4 | Loss -1.2814998626708984e-06\nStep: 9 | Iter: 5 | Loss -1.3262033462524414e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 10 | Iter: 1 | Loss -1.4156103134155273e-06\nStep: 10 | Iter: 2 | Loss -1.2665987014770508e-06\nStep: 10 | Iter: 3 | Loss -1.0505318641662598e-06\nStep: 10 | Iter: 4 | Loss -1.2814998626708984e-06\nStep: 10 | Iter: 5 | Loss -1.3560056686401367e-06\nStep: 10 | Format: 0.01 | Accuracy: 0.0\nOutput example: $18.00\n\n1.  <reasoning>\n2.  <answer>\n3.  <reasoning>\n4.  <answer>\n\n<explanation>\n<reasoning>\n<answer>\n<reasoning>\n<answer>\n<explanation>\n<answer>\n<explanation>\n<answer>\n<explanation>\n\n1.  $18.00/hr=1800$/hr.\n2.  $1800/5=4800$/hr.\n3.  $1800/10=2400$/hr.\n4.  $2400/5=4800$/hr.\n5.  $4800$/hr.\n6.  4800/10=2400$/hr.\n7.  $2400/15=1600$/hr.\n8.  $1600$/hr.\n9.  $1600/10=2400$/hr.\n10.  $2400/15=4800$/hr.\n11.  $4800$/hr.\n\n**In the following questions, you are given two sentences and asked to write out a justification for each sentence, that is, justify why it is correct, or why the sentence is grammatically incorrect.**\n1.  You were at work when an employee called you at 2 p.m. and asked you to work until 5 p.m.  Why did you work?\n2.  You worked hard to get the job done, and you were happy to learn the hard way.  You did not want to give up your job.\n3.  You did not get any money.\n4.  You do not like this job.\n5.  You like the work.\n6.  You get paid more than the other people.\n7.  You are a good employee.\n8.  You are a good employee.\n9.  You work all day, so you deserve to get paid.\n\n1.  You did not work hard to get the job done, and you did not want to give up your job.\n2.  You did not get any money.\n3.  You did not get paid\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.53s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 11 | Iter: 1 | Loss -6.221234798431396e-07\nStep: 11 | Iter: 2 | Loss -7.636845111846924e-07\nStep: 11 | Iter: 3 | Loss -7.040798664093018e-07\nStep: 11 | Iter: 4 | Loss -8.23289155960083e-07\nStep: 11 | Iter: 5 | Loss -8.23289155960083e-07\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 12 | Iter: 1 | Loss -1.1473894119262695e-06\nStep: 12 | Iter: 2 | Loss -1.1324882507324219e-06\nStep: 12 | Iter: 3 | Loss -9.685754776000977e-07\nStep: 12 | Iter: 4 | Loss -1.1175870895385742e-06\nStep: 12 | Iter: 5 | Loss -1.125037670135498e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 13 | Iter: 1 | Loss -6.817281246185303e-07\nStep: 13 | Iter: 2 | Loss -7.152557373046875e-07\nStep: 13 | Iter: 3 | Loss -7.748603820800781e-07\nStep: 13 | Iter: 4 | Loss -9.313225746154785e-07\nStep: 13 | Iter: 5 | Loss -6.854534149169922e-07\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 14 | Iter: 1 | Loss -1.0281801223754883e-06\nStep: 14 | Iter: 2 | Loss -1.3560056686401367e-06\nStep: 14 | Iter: 3 | Loss -1.1920928955078125e-06\nStep: 14 | Iter: 4 | Loss -1.1473894119262695e-06\nStep: 14 | Iter: 5 | Loss -1.0356307029724121e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.57s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 15 | Iter: 1 | Loss -2.115964889526367e-06\nStep: 15 | Iter: 2 | Loss -2.2649765014648438e-06\nStep: 15 | Iter: 3 | Loss -2.16066837310791e-06\nStep: 15 | Iter: 4 | Loss -2.115964889526367e-06\nStep: 15 | Iter: 5 | Loss -2.1904706954956055e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.61s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 16 | Iter: 1 | Loss -2.2351741790771484e-06\nStep: 16 | Iter: 2 | Loss -2.4139881134033203e-06\nStep: 16 | Iter: 3 | Loss -2.3543834686279297e-06\nStep: 16 | Iter: 4 | Loss -2.205371856689453e-06\nStep: 16 | Iter: 5 | Loss -2.3990869522094727e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.56s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 17 | Iter: 1 | Loss -2.7418136596679688e-06\nStep: 17 | Iter: 2 | Loss -3.0994415283203125e-06\nStep: 17 | Iter: 3 | Loss -2.6673078536987305e-06\nStep: 17 | Iter: 4 | Loss -3.0994415283203125e-06\nStep: 17 | Iter: 5 | Loss -3.2633543014526367e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 18 | Iter: 1 | Loss -2.250075340270996e-06\nStep: 18 | Iter: 2 | Loss -2.1904706954956055e-06\nStep: 18 | Iter: 3 | Loss -2.086162567138672e-06\nStep: 18 | Iter: 4 | Loss -2.2649765014648438e-06\nStep: 18 | Iter: 5 | Loss -2.16066837310791e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.55s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 19 | Iter: 1 | Loss -1.2665987014770508e-06\nStep: 19 | Iter: 2 | Loss -1.1101365089416504e-06\nStep: 19 | Iter: 3 | Loss -1.0505318641662598e-06\nStep: 19 | Iter: 4 | Loss -1.0952353477478027e-06\nStep: 19 | Iter: 5 | Loss -1.2516975402832031e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.61s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 20 | Iter: 1 | Loss nan\nStep: 20 | Iter: 2 | Loss nan\nStep: 20 | Iter: 3 | Loss nan\nStep: 20 | Iter: 4 | Loss nan\nStep: 20 | Iter: 5 | Loss nan\nStep: 20 | Format: 0.005 | Accuracy: 0.0\nOutput example: I'll try to ride a little faster in the first week.\nTim:  I'll try to ride a little faster in the second week.\nTim:  I'll try to ride a little faster in the third week.\nTim:  I'll try to ride a little faster in the fourth week.\nTim:  I'll try to ride a little faster in the fifth week.\n\nI'll check this form out and let you know the results.\n\nYou can do the same thing with the following.\n<reasoning>\n...\n</reasoning>\n<answer>\n...\n</answer>\nUser: You can also use the following:\n<reasoning>\n...\n</reasoning>\n<answer>\n...\n</answer>\nUser:  I'll try to see if I can figure this out.  Is it a bit tricky to do a whole week.\nTim:  It's tricky to do a whole week.  I can't figure it out.\nTim:  It's tricky to do a whole week.\nTim:  I can't figure it out.  I think I'll try the next week.\nTim:  I'll try to see if I can figure out this week.  Can you go through the whole week?\nTim:  I can't figure out this week.  Can you do the whole week?\n\nI'll check that out.\nUser:  Can you do the whole week?\nTim:  Yes.  I'll try to do the whole week.\nTim:  I'll try to do the whole week.\nTim:  I think I'll try the next week.\nTim:  I'll try to see if I can figure out this week.  Can you go through the whole week?\nTim:  I can't figure out this week.  Can you do the whole week?\nTim:  Yes.  I'll try to see if I can figure out this week.  Can you do the whole week?\nTim:  I can't figure out this week.  Can you do the whole week?\n\nLet me know if you need help.  Tim rides his bike to work every day.  If he rides less than 25 miles per week, how much time does he spend biking?\n\nLet me check that out\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.45s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 21 | Iter: 1 | Loss -2.16066837310791e-06\nStep: 21 | Iter: 2 | Loss -2.5033950805664062e-06\nStep: 21 | Iter: 3 | Loss -2.339482307434082e-06\nStep: 21 | Iter: 4 | Loss -2.6971101760864258e-06\nStep: 21 | Iter: 5 | Loss -2.3990869522094727e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 22 | Iter: 1 | Loss -3.293156623840332e-06\nStep: 22 | Iter: 2 | Loss -3.1888484954833984e-06\nStep: 22 | Iter: 3 | Loss -3.427267074584961e-06\nStep: 22 | Iter: 4 | Loss -3.814697265625e-06\nStep: 22 | Iter: 5 | Loss -4.082918167114258e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.53s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 23 | Iter: 1 | Loss -2.5033950805664062e-06\nStep: 23 | Iter: 2 | Loss -3.0100345611572266e-06\nStep: 23 | Iter: 3 | Loss -3.0994415283203125e-06\nStep: 23 | Iter: 4 | Loss -2.8908252716064453e-06\nStep: 23 | Iter: 5 | Loss -2.6673078536987305e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.58s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 24 | Iter: 1 | Loss -1.6316771507263184e-06\nStep: 24 | Iter: 2 | Loss -1.3187527656555176e-06\nStep: 24 | Iter: 3 | Loss -1.4454126358032227e-06\nStep: 24 | Iter: 4 | Loss -1.6316771507263184e-06\nStep: 24 | Iter: 5 | Loss -1.4007091522216797e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.70s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 25 | Iter: 1 | Loss 0.0003910064697265625\nStep: 25 | Iter: 2 | Loss -0.0152587890625\nStep: 25 | Iter: 3 | Loss -0.03564453125\nStep: 25 | Iter: 4 | Loss -0.05419921875\nStep: 25 | Iter: 5 | Loss -0.0625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 26 | Iter: 1 | Loss -1.043081283569336e-05\nStep: 26 | Iter: 2 | Loss -1.2099742889404297e-05\nStep: 26 | Iter: 3 | Loss -1.6927719116210938e-05\nStep: 26 | Iter: 4 | Loss -1.9431114196777344e-05\nStep: 26 | Iter: 5 | Loss -2.8014183044433594e-05\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 27 | Iter: 1 | Loss -9.632110595703125e-05\nStep: 27 | Iter: 2 | Loss -0.00011682510375976562\nStep: 27 | Iter: 3 | Loss -0.0001277923583984375\nStep: 27 | Iter: 4 | Loss -0.00014495849609375\nStep: 27 | Iter: 5 | Loss -0.0001583099365234375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.34s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 28 | Iter: 1 | Loss -3.981590270996094e-05\nStep: 28 | Iter: 2 | Loss -4.076957702636719e-05\nStep: 28 | Iter: 3 | Loss -4.458427429199219e-05\nStep: 28 | Iter: 4 | Loss -4.76837158203125e-05\nStep: 28 | Iter: 5 | Loss -4.744529724121094e-05\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 29 | Iter: 1 | Loss -0.00010967254638671875\nStep: 29 | Iter: 2 | Loss -0.00011157989501953125\nStep: 29 | Iter: 3 | Loss -0.00012493133544921875\nStep: 29 | Iter: 4 | Loss -0.0001239776611328125\nStep: 29 | Iter: 5 | Loss -0.0001277923583984375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 30 | Iter: 1 | Loss -0.00014781951904296875\nStep: 30 | Iter: 2 | Loss -0.0001583099365234375\nStep: 30 | Iter: 3 | Loss -0.00014972686767578125\nStep: 30 | Iter: 4 | Loss -0.00016117095947265625\nStep: 30 | Iter: 5 | Loss -0.000156402587890625\nStep: 30 | Format: 0.0033333333333333335 | Accuracy: 0.013333333333333334\nOutput example: Mrs. Snyder's income is $48,400.00.<eos> How much was Mrs. Snyder's previous monthly income?\nMrs. Snyder used to spend 40% of her monthly income on rent and utilities. Her salary was recently increased by $600 so now her rent and utilities only amount to 25% of her monthly income. How much was Mrs. Snyder's previous monthly income?\nMrs. Snyder's income is $48,400.00.\n40% of 40% of her income is 16,000.00.\nMrs. Snyder's previous income is $15,000.00.\nMrs. Snyder's income is $48,400.00.\nMrs. Snyder's income is $48,400.00.\nMrs. Snyder uses 16,000.00 in groceries.\nMrs. Snyder uses 16,000.00 in rent and utilities.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in her income.\nMrs. Snyder uses 16,000.00 in\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 31 | Iter: 1 | Loss -0.00016689300537109375\nStep: 31 | Iter: 2 | Loss -0.0001659393310546875\nStep: 31 | Iter: 3 | Loss -0.00016880035400390625\nStep: 31 | Iter: 4 | Loss -0.00017833709716796875\nStep: 31 | Iter: 5 | Loss -0.00017452239990234375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.55s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 32 | Iter: 1 | Loss -0.0002727508544921875\nStep: 32 | Iter: 2 | Loss -0.000278472900390625\nStep: 32 | Iter: 3 | Loss -0.000278472900390625\nStep: 32 | Iter: 4 | Loss -0.0002841949462890625\nStep: 32 | Iter: 5 | Loss -0.00028228759765625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.58s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 33 | Iter: 1 | Loss -0.00054168701171875\nStep: 33 | Iter: 2 | Loss -0.000579833984375\nStep: 33 | Iter: 3 | Loss -0.000629425048828125\nStep: 33 | Iter: 4 | Loss -0.00066375732421875\nStep: 33 | Iter: 5 | Loss -0.00064849853515625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 34 | Iter: 1 | Loss -0.00011301040649414062\nStep: 34 | Iter: 2 | Loss -0.00011301040649414062\nStep: 34 | Iter: 3 | Loss -0.00011301040649414062\nStep: 34 | Iter: 4 | Loss -0.00011587142944335938\nStep: 34 | Iter: 5 | Loss -0.00011920928955078125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 35 | Iter: 1 | Loss -0.0003662109375\nStep: 35 | Iter: 2 | Loss -0.000385284423828125\nStep: 35 | Iter: 3 | Loss -0.000385284423828125\nStep: 35 | Iter: 4 | Loss -0.000385284423828125\nStep: 35 | Iter: 5 | Loss -0.0003910064697265625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.42s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 36 | Iter: 1 | Loss -0.000278472900390625\nStep: 36 | Iter: 2 | Loss -0.0002841949462890625\nStep: 36 | Iter: 3 | Loss -0.000274658203125\nStep: 36 | Iter: 4 | Loss -0.000301361083984375\nStep: 36 | Iter: 5 | Loss -0.00030517578125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.41s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 37 | Iter: 1 | Loss -0.000396728515625\nStep: 37 | Iter: 2 | Loss -0.0004024505615234375\nStep: 37 | Iter: 3 | Loss -0.00042724609375\nStep: 37 | Iter: 4 | Loss -0.0004177093505859375\nStep: 37 | Iter: 5 | Loss -0.0004367828369140625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 38 | Iter: 1 | Loss -0.0002288818359375\nStep: 38 | Iter: 2 | Loss -0.00023174285888671875\nStep: 38 | Iter: 3 | Loss -0.0002307891845703125\nStep: 38 | Iter: 4 | Loss -0.0002346038818359375\nStep: 38 | Iter: 5 | Loss -0.0002307891845703125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.60s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 39 | Iter: 1 | Loss -0.000408172607421875\nStep: 39 | Iter: 2 | Loss -0.0004329681396484375\nStep: 39 | Iter: 3 | Loss -0.0004520416259765625\nStep: 39 | Iter: 4 | Loss -0.0004482269287109375\nStep: 39 | Iter: 5 | Loss -0.00049591064453125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.40s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 40 | Iter: 1 | Loss -0.0003719329833984375\nStep: 40 | Iter: 2 | Loss -0.000362396240234375\nStep: 40 | Iter: 3 | Loss -0.000370025634765625\nStep: 40 | Iter: 4 | Loss -0.000370025634765625\nStep: 40 | Iter: 5 | Loss -0.0003719329833984375\nStep: 40 | Format: 0.0025 | Accuracy: 0.01\nOutput example: Anna has 15 pieces of candy and Billy has 12. How many more pieces of candy does Anna have than Billy?\nComment: Anna thinks the number of pieces of candy is a decimal because she knows how many pieces she got.<eos>Anna is 12 years old and Billy is 14.<eos>Anna thinks that the total amount of candy she got is 20 pieces.\nAnna is 13 years old and Billy is 15.<eos>Anna thinks that the total amount of candy she got is 25 pieces.\n\n<h2>Solution</h2><eos>Write a comment on Anna's reasoning.\nAnna is 13 years old and Billy is 15.\nAnna thinks that the total amount of candy she got is 20 pieces.\nAnna is 12 years old and Billy is 14.\n\nAnna is 13 years old and Billy is 15.\nAnna thinks that the total amount of candy she got is 20 pieces.\nAnna is 12 years old and Billy is 14.\n\nAnna thinks that the number of pieces of candy Billy gets is the same as Anna thinks the total number of candy she got is 25 pieces.\nAnna is 13 years old and Billy is 15.\n\nAnna is 13 years old and Billy is 15.\n\nAnna is 13 years old and Billy is 15.\n\nAnna is 13 years old and Billy is 15.\n\nAnna is 13 years old and Billy is 15.\nAnna is 13 years old and Billy is 15.<eos>Anna is 13 years old and Billy is 15.\n\nAnna is 13 years old and Billy is 15.\n\nAnna is 13 years old and Billy is 15.\n\nAnna is 13 years old and Billy is 15.\n\nAnna is 13 years old and Billy is 15.\n\nAnna is 13 years old and Billy is 15.\n\nAnna is 13 years old and Billy is 15.\n\nAnna is 13 years old and Billy is 15.<eos>Anna is 13 years old and Billy is 15.\n\nAnna is 13 years old and Billy is 15.\n\nAnna is 13 years old and Billy is 15.\n\nAnna is\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.72s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 41 | Iter: 1 | Loss -0.00034332275390625\nStep: 41 | Iter: 2 | Loss -0.000347137451171875\nStep: 41 | Iter: 3 | Loss -0.0003566741943359375\nStep: 41 | Iter: 4 | Loss -0.00035858154296875\nStep: 41 | Iter: 5 | Loss -0.000354766845703125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.75s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 42 | Iter: 1 | Loss -0.000293731689453125\nStep: 42 | Iter: 2 | Loss -0.0002956390380859375\nStep: 42 | Iter: 3 | Loss -0.0003108978271484375\nStep: 42 | Iter: 4 | Loss -0.00030517578125\nStep: 42 | Iter: 5 | Loss -0.000339508056640625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.79s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 43 | Iter: 1 | Loss -0.000301361083984375\nStep: 43 | Iter: 2 | Loss -0.0003108978271484375\nStep: 43 | Iter: 3 | Loss -0.0003070831298828125\nStep: 43 | Iter: 4 | Loss -0.000316619873046875\nStep: 43 | Iter: 5 | Loss -0.0003204345703125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.71s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 44 | Iter: 1 | Loss -0.000286102294921875\nStep: 44 | Iter: 2 | Loss -0.0002880096435546875\nStep: 44 | Iter: 3 | Loss -0.00029754638671875\nStep: 44 | Iter: 4 | Loss -0.000286102294921875\nStep: 44 | Iter: 5 | Loss -0.000301361083984375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.76s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 45 | Iter: 1 | Loss -0.0003108978271484375\nStep: 45 | Iter: 2 | Loss -0.000316619873046875\nStep: 45 | Iter: 3 | Loss -0.0003299713134765625\nStep: 45 | Iter: 4 | Loss -0.0003261566162109375\nStep: 45 | Iter: 5 | Loss -0.0003261566162109375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.80s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 46 | Iter: 1 | Loss -0.000514984130859375\nStep: 46 | Iter: 2 | Loss -0.00052642822265625\nStep: 46 | Iter: 3 | Loss -0.000537872314453125\nStep: 46 | Iter: 4 | Loss -0.00052642822265625\nStep: 46 | Iter: 5 | Loss -0.000537872314453125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.82s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 47 | Iter: 1 | Loss -0.0004329681396484375\nStep: 47 | Iter: 2 | Loss -0.000438690185546875\nStep: 47 | Iter: 3 | Loss -0.000457763671875\nStep: 47 | Iter: 4 | Loss -0.000457763671875\nStep: 47 | Iter: 5 | Loss -0.000453948974609375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.78s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 48 | Iter: 1 | Loss -0.00019550323486328125\nStep: 48 | Iter: 2 | Loss -0.0001983642578125\nStep: 48 | Iter: 3 | Loss -0.00020122528076171875\nStep: 48 | Iter: 4 | Loss -0.00020599365234375\nStep: 48 | Iter: 5 | Loss -0.0002079010009765625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.58s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 49 | Iter: 1 | Loss -0.000946044921875\nStep: 49 | Iter: 2 | Loss -0.0009765625\nStep: 49 | Iter: 3 | Loss -0.0009918212890625\nStep: 49 | Iter: 4 | Loss -0.0010223388671875\nStep: 49 | Iter: 5 | Loss -0.0010528564453125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.88s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 50 | Iter: 1 | Loss -0.000507354736328125\nStep: 50 | Iter: 2 | Loss -0.000518798828125\nStep: 50 | Iter: 3 | Loss -0.00052642822265625\nStep: 50 | Iter: 4 | Loss -0.000537872314453125\nStep: 50 | Iter: 5 | Loss -0.000568389892578125\nStep: 50 | Format: 0.002 | Accuracy: 0.008\nOutput example: If Laurie has 4 shells, how many shells did Alan collect?<eos><eos><eos><eos><eos><eos><eos><eos>\n\n<h2>Related Content</h2>\n\n* Question 1: Who does Alan collect?\n* Question 2: Why does he collect?\n* Question 3: What else did Alan collect?<eos> <h3>What is the Reason For Collecting?</h3>\n\n* Question 1: The reason for collecting is to help the planet.\n* Question 2: Alan collected the shells because it is a treasure.\n* Question 3: Alan collects for his family.\n* Question 4: Alan collects because he wants to keep the shells in his collection.<eos> <h3>Why is Alan Collecting?</h3>\n\n* Question 5: Alan is collecting for his family because he is a child.\n* Question 6: Alan is collecting because he has to protect the shells.\n* Question 7: Alan is collecting for his family because it is important for them to collect the shells.\n* Question 8: Alan is collecting for his family because it is fun.\n* Question 9: Alan is collecting for his family because it is a fun hobby.\n* Question 10: Alan is collecting for his family because he would like to do something fun with the shells.<eos> <h3>Why is Alan Collecting?</h3>\n\n* Question 11: Alan is collecting for his family because he is a child.\n* Question 12: Alan is collecting for his family because it is a fun hobby.\n* Question 13: Alan is collecting for his family because it is a fun hobby.\n* Question 14: Alan is collecting for his family because it is fun.\n* Question 15: Alan is collecting because he wants to keep the shells in his collection.<eos> <h3>Why is Alan Collecting?</h3><eos> <h3>Why is Alan Collecting?</h3>\n\nAlan is collecting because he loves the shells. He loves the shells. He loves the shells. He loves the shells. Alan is collecting because he wants to keep the shells in his collection. He has been collecting for years. He has collected the shells for a long time. He has been collecting the shells for a long time. Alan is collecting for his family. He collects the shells for his family. He is collecting the shells because his family wants the shells. Alan collects the shells because he loves them. He is collecting the shells because he is a child. Alan is collecting the shells because he is a child\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.81s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 51 | Iter: 1 | Loss -0.0011749267578125\nStep: 51 | Iter: 2 | Loss -0.00118255615234375\nStep: 51 | Iter: 3 | Loss -0.00122833251953125\nStep: 51 | Iter: 4 | Loss -0.0012664794921875\nStep: 51 | Iter: 5 | Loss -0.0012969970703125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.88s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 52 | Iter: 1 | Loss -0.0015106201171875\nStep: 52 | Iter: 2 | Loss -0.0016632080078125\nStep: 52 | Iter: 3 | Loss -0.0016632080078125\nStep: 52 | Iter: 4 | Loss -0.0018310546875\nStep: 52 | Iter: 5 | Loss -0.0020294189453125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:30<00:00, 30.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 53 | Iter: 1 | Loss -0.00072479248046875\nStep: 53 | Iter: 2 | Loss -0.000762939453125\nStep: 53 | Iter: 3 | Loss -0.00077056884765625\nStep: 53 | Iter: 4 | Loss -0.00079345703125\nStep: 53 | Iter: 5 | Loss -0.000804901123046875\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.61s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 54 | Iter: 1 | Loss nan\nStep: 54 | Iter: 2 | Loss nan\nStep: 54 | Iter: 3 | Loss nan\nStep: 54 | Iter: 4 | Loss nan\nStep: 54 | Iter: 5 | Loss nan\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.67s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 55 | Iter: 1 | Loss -0.0018463134765625\nStep: 55 | Iter: 2 | Loss -0.0018768310546875\nStep: 55 | Iter: 3 | Loss -0.001983642578125\nStep: 55 | Iter: 4 | Loss -0.00201416015625\nStep: 55 | Iter: 5 | Loss -0.0022125244140625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.64s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 56 | Iter: 1 | Loss -0.00130462646484375\nStep: 56 | Iter: 2 | Loss -0.0013885498046875\nStep: 56 | Iter: 3 | Loss -0.0014801025390625\nStep: 56 | Iter: 4 | Loss -0.00156402587890625\nStep: 56 | Iter: 5 | Loss -0.0018310546875\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.63s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 57 | Iter: 1 | Loss -0.000652313232421875\nStep: 57 | Iter: 2 | Loss -0.00066375732421875\nStep: 57 | Iter: 3 | Loss -0.000690460205078125\nStep: 57 | Iter: 4 | Loss -0.00070953369140625\nStep: 57 | Iter: 5 | Loss -0.00074005126953125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.63s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 58 | Iter: 1 | Loss -0.002349853515625\nStep: 58 | Iter: 2 | Loss -0.0023651123046875\nStep: 58 | Iter: 3 | Loss -0.0023956298828125\nStep: 58 | Iter: 4 | Loss -0.00244140625\nStep: 58 | Iter: 5 | Loss -0.0025177001953125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.67s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 59 | Iter: 1 | Loss -0.002716064453125\nStep: 59 | Iter: 2 | Loss -0.0030670166015625\nStep: 59 | Iter: 3 | Loss -0.004791259765625\nStep: 59 | Iter: 4 | Loss -0.017333984375\nStep: 59 | Iter: 5 | Loss -0.310546875\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.79s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 60 | Iter: 1 | Loss -0.0032501220703125\nStep: 60 | Iter: 2 | Loss -0.003265380859375\nStep: 60 | Iter: 3 | Loss -0.0034637451171875\nStep: 60 | Iter: 4 | Loss -0.003509521484375\nStep: 60 | Iter: 5 | Loss -0.0035400390625\nStep: 60 | Format: 0.0016666666666666668 | Accuracy: 0.006666666666666667\nOutput example: Joanne bought 35 coins.<eos><eos><eos>\n\nThe assistant collected the remaining 15 coins.<eos><eos><eos>\n\nThe total amount Joanne has now is $<eos><eos><eos><eos>\n\nThe assistant has to pay the cashier $1.50.<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n\n<h2>Next:</h2><eos><eos><eos>\n\nThe cashier pays Joanne 22.50.<eos><eos><eos><eos>\n\nThe cashier uses the remaining 13.50 of his money to buy the soda.<eos><eos>\n\nHow much money does Joanne have now?<eos>\n\n<h3>Additional Information</h3>\n\nFor the next four hours, the cashier has $ 10.50 left.<eos>\n\n<h2>Discussion Questions</h2><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n\nThe total amount of money the cashier has now is $ $ $<eos><eos><eos><eos><eos>\n\nThe cashier can spend $ $ $ $ $<eos> on the following items.<eos>\n\nThe cashier has the remaining 15 coins.\n\n<h3>What Is the Amount?</h3><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n\n<h2>What else is going on?</h2>\n\nThe cashier has the remaining $ $ $ $ $ dollars.<eos><eos>\n\nThe cashier has the remaining $ $ $ $ dollars.<eos>\n\n<h2>Final Thoughts</h2><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n\n<h2>Questions</h2><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n\n<h2>Works Cited</h2><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n\n<h3>Additional Information</h3>\n\nA customer has decided to buy 12.50 dollars worth of candy at the store.<eos>\n\n* The candy cost 1.25 dollars less than the previous purchase.<eos>* The cost is now 1.50 dollars less.\n\nHow much more is the candy?<eos><eos><eos><eos><eos><eos><eos><eos>\n\n<h3>More Information</h3>\n\nThe candy cost $1.25.\n\nThe candy will be sold at the store for $1.50.\n\n<h2>Work and Materials</h2>\n\n1.\n\n<h2>Step 1</h2>\n\nCalculate the amount of candy.\n\n<h2>Step 2</h2>\n\nDivide the amount of candy by the cost.\n\n<h2>Step 3</h2>\n\nThe cost of the candy is $1.50.<eos><eos>\n\n<h2>Step 4</h2>\n\nSubstitute the cost into the number of candies:\n\n$1.50<eos><eos>\n\n<h2>Final Thoughts</h2>\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.76s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 61 | Iter: 1 | Loss -0.002960205078125\nStep: 61 | Iter: 2 | Loss -0.0030517578125\nStep: 61 | Iter: 3 | Loss -0.003082275390625\nStep: 61 | Iter: 4 | Loss -0.003143310546875\nStep: 61 | Iter: 5 | Loss -0.003326416015625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.72s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 62 | Iter: 1 | Loss -0.002838134765625\nStep: 62 | Iter: 2 | Loss -0.002838134765625\nStep: 62 | Iter: 3 | Loss -0.002899169921875\nStep: 62 | Iter: 4 | Loss -0.002960205078125\nStep: 62 | Iter: 5 | Loss -0.0030059814453125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.65s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 63 | Iter: 1 | Loss -0.003753662109375\nStep: 63 | Iter: 2 | Loss -0.0037841796875\nStep: 63 | Iter: 3 | Loss -0.0038604736328125\nStep: 63 | Iter: 4 | Loss -0.003875732421875\nStep: 63 | Iter: 5 | Loss -0.00396728515625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.77s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 64 | Iter: 1 | Loss -0.0078125\nStep: 64 | Iter: 2 | Loss -0.00799560546875\nStep: 64 | Iter: 3 | Loss -0.008056640625\nStep: 64 | Iter: 4 | Loss -0.0081787109375\nStep: 64 | Iter: 5 | Loss -0.0084228515625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.68s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 65 | Iter: 1 | Loss -0.00848388671875\nStep: 65 | Iter: 2 | Loss -0.0086669921875\nStep: 65 | Iter: 3 | Loss -0.00885009765625\nStep: 65 | Iter: 4 | Loss -0.00897216796875\nStep: 65 | Iter: 5 | Loss -0.00909423828125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.62s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 66 | Iter: 1 | Loss -0.008544921875\nStep: 66 | Iter: 2 | Loss -0.0086669921875\nStep: 66 | Iter: 3 | Loss -0.0087890625\nStep: 66 | Iter: 4 | Loss -0.00885009765625\nStep: 66 | Iter: 5 | Loss -0.0089111328125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.69s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 67 | Iter: 1 | Loss -0.0084228515625\nStep: 67 | Iter: 2 | Loss -0.00860595703125\nStep: 67 | Iter: 3 | Loss -0.0086669921875\nStep: 67 | Iter: 4 | Loss -0.00872802734375\nStep: 67 | Iter: 5 | Loss -0.00885009765625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.40s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 68 | Iter: 1 | Loss -0.01019287109375\nStep: 68 | Iter: 2 | Loss -0.01019287109375\nStep: 68 | Iter: 3 | Loss -0.01019287109375\nStep: 68 | Iter: 4 | Loss -0.01025390625\nStep: 68 | Iter: 5 | Loss -0.01019287109375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 69 | Iter: 1 | Loss -0.01068115234375\nStep: 69 | Iter: 2 | Loss -0.0107421875\nStep: 69 | Iter: 3 | Loss -0.0107421875\nStep: 69 | Iter: 4 | Loss -0.0107421875\nStep: 69 | Iter: 5 | Loss -0.0108642578125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.75s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 70 | Iter: 1 | Loss -0.0118408203125\nStep: 70 | Iter: 2 | Loss -0.011962890625\nStep: 70 | Iter: 3 | Loss -0.01202392578125\nStep: 70 | Iter: 4 | Loss -0.01202392578125\nStep: 70 | Iter: 5 | Loss -0.01214599609375\nStep: 70 | Format: 0.0014285714285714286 | Accuracy: 0.005714285714285714\nOutput example: <eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n\n<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos> to give the animals the<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> . .<eos> .<eos> .<eos> .\n\n<eos> .<eos> .<eos> . .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> .<eos> . .<eos> .<eos> . .<eos> .<eos> .<eos> . .<eos> .<eos> .\n\n<eos> . .<eos> . .<eos> .<eos> . .<eos> .\n\n<eos> . . .\n\n<eos> . . .<eos> . . .<eos> . . . .<eos> . . . . .<eos> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .<eos> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .<eos> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .<eos> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .<eos> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .<eos> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .<eos> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 71 | Iter: 1 | Loss -0.0130615234375\nStep: 71 | Iter: 2 | Loss -0.0130615234375\nStep: 71 | Iter: 3 | Loss -0.0130615234375\nStep: 71 | Iter: 4 | Loss -0.0130615234375\nStep: 71 | Iter: 5 | Loss -0.0130615234375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.69s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 72 | Iter: 1 | Loss -0.0108642578125\nStep: 72 | Iter: 2 | Loss -0.0108642578125\nStep: 72 | Iter: 3 | Loss -0.0108642578125\nStep: 72 | Iter: 4 | Loss -0.0108642578125\nStep: 72 | Iter: 5 | Loss -0.0108642578125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.37s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 73 | Iter: 1 | Loss -0.0118408203125\nStep: 73 | Iter: 2 | Loss -0.0118408203125\nStep: 73 | Iter: 3 | Loss -0.0118408203125\nStep: 73 | Iter: 4 | Loss -0.0118408203125\nStep: 73 | Iter: 5 | Loss -0.0118408203125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.41s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 74 | Iter: 1 | Loss -0.0130615234375\nStep: 74 | Iter: 2 | Loss -0.0130615234375\nStep: 74 | Iter: 3 | Loss -0.0130615234375\nStep: 74 | Iter: 4 | Loss -0.0130615234375\nStep: 74 | Iter: 5 | Loss -0.0130615234375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 75 | Iter: 1 | Loss nan\nStep: 75 | Iter: 2 | Loss nan\nStep: 75 | Iter: 3 | Loss nan\nStep: 75 | Iter: 4 | Loss nan\nStep: 75 | Iter: 5 | Loss nan\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 76 | Iter: 1 | Loss -0.0130615234375\nStep: 76 | Iter: 2 | Loss -0.0130615234375\nStep: 76 | Iter: 3 | Loss -0.0130615234375\nStep: 76 | Iter: 4 | Loss -0.0130615234375\nStep: 76 | Iter: 5 | Loss -0.0130615234375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 77 | Iter: 1 | Loss nan\nStep: 77 | Iter: 2 | Loss nan\nStep: 77 | Iter: 3 | Loss nan\nStep: 77 | Iter: 4 | Loss nan\nStep: 77 | Iter: 5 | Loss nan\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.31s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 78 | Iter: 1 | Loss nan\nStep: 78 | Iter: 2 | Loss nan\nStep: 78 | Iter: 3 | Loss nan\nStep: 78 | Iter: 4 | Loss nan\nStep: 78 | Iter: 5 | Loss nan\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 79 | Iter: 1 | Loss -0.0123291015625\nStep: 79 | Iter: 2 | Loss -0.0123291015625\nStep: 79 | Iter: 3 | Loss -0.0123291015625\nStep: 79 | Iter: 4 | Loss -0.0123291015625\nStep: 79 | Iter: 5 | Loss -0.0123291015625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.03s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 80 | Iter: 1 | Loss -0.0146484375\nStep: 80 | Iter: 2 | Loss -0.0146484375\nStep: 80 | Iter: 3 | Loss -0.0146484375\nStep: 80 | Iter: 4 | Loss -0.0146484375\nStep: 80 | Iter: 5 | Loss -0.0146484375\nStep: 80 | Format: 0.00125 | Accuracy: 0.005\nOutput example: <eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>ly<eos>\n\n<eos><eos><eos><eos>ly<eos><eos><eos>ly<eos><eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos><eos>ly<eos>ly<eos><eos>ly<eos>ly<eos><eos><eos>ly<eos>ly<eos><eos>ly<eos>ly<eos><eos><eos><eos>ly<eos><eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>ly<eos>\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.10s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 81 | Iter: 1 | Loss -0.01165771484375\nStep: 81 | Iter: 2 | Loss -0.01165771484375\nStep: 81 | Iter: 3 | Loss -0.01165771484375\nStep: 81 | Iter: 4 | Loss -0.01165771484375\nStep: 81 | Iter: 5 | Loss -0.01165771484375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.13s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 82 | Iter: 1 | Loss nan\nStep: 82 | Iter: 2 | Loss nan\nStep: 82 | Iter: 3 | Loss nan\nStep: 82 | Iter: 4 | Loss nan\nStep: 82 | Iter: 5 | Loss nan\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.55s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 83 | Iter: 1 | Loss nan\nStep: 83 | Iter: 2 | Loss nan\nStep: 83 | Iter: 3 | Loss nan\nStep: 83 | Iter: 4 | Loss nan\nStep: 83 | Iter: 5 | Loss nan\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 84 | Iter: 1 | Loss -0.0125732421875\nStep: 84 | Iter: 2 | Loss -0.0125732421875\nStep: 84 | Iter: 3 | Loss -0.0125732421875\nStep: 84 | Iter: 4 | Loss -0.0125732421875\nStep: 84 | Iter: 5 | Loss -0.0125732421875\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.59s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 85 | Iter: 1 | Loss -0.0146484375\nStep: 85 | Iter: 2 | Loss -0.0146484375\nStep: 85 | Iter: 3 | Loss -0.0146484375\nStep: 85 | Iter: 4 | Loss -0.0146484375\nStep: 85 | Iter: 5 | Loss -0.0146484375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.67s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 86 | Iter: 1 | Loss -0.01141357421875\nStep: 86 | Iter: 2 | Loss -0.01141357421875\nStep: 86 | Iter: 3 | Loss -0.01141357421875\nStep: 86 | Iter: 4 | Loss -0.01141357421875\nStep: 86 | Iter: 5 | Loss -0.01141357421875\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.66s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 87 | Iter: 1 | Loss -0.0142822265625\nStep: 87 | Iter: 2 | Loss -0.0142822265625\nStep: 87 | Iter: 3 | Loss -0.0142822265625\nStep: 87 | Iter: 4 | Loss -0.0142822265625\nStep: 87 | Iter: 5 | Loss -0.0142822265625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 88 | Iter: 1 | Loss -0.01348876953125\nStep: 88 | Iter: 2 | Loss -0.01348876953125\nStep: 88 | Iter: 3 | Loss -0.01348876953125\nStep: 88 | Iter: 4 | Loss -0.01348876953125\nStep: 88 | Iter: 5 | Loss -0.01348876953125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.76s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 89 | Iter: 1 | Loss -0.0125732421875\nStep: 89 | Iter: 2 | Loss -0.0125732421875\nStep: 89 | Iter: 3 | Loss -0.0125732421875\nStep: 89 | Iter: 4 | Loss -0.0125732421875\nStep: 89 | Iter: 5 | Loss -0.0125732421875\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.69s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 90 | Iter: 1 | Loss nan\nStep: 90 | Iter: 2 | Loss nan\nStep: 90 | Iter: 3 | Loss nan\nStep: 90 | Iter: 4 | Loss nan\nStep: 90 | Iter: 5 | Loss nan\nStep: 90 | Format: 0.0011111111111111111 | Accuracy: 0.0044444444444444444\nOutput example: <eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n\n<eos><eos><eos><eos><eos>\n\n<eos><eos><eos><eos><eos><eos><eos><eos>\n\n<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n\n<eos><eos>\n\n<eos>\n\n<eos><eos>\n\n<eos>\n\n<eos><eos>\n\n<eos><eos>\n\n<eos><eos>\n\n<eos><eos><eos>\n\n<eos>\n\n<eos>\n\n<eos><eos>\n\n<eos>\n\n<eos><eos><eos>\n\nThe answer should be in the form of a number.<eos>\n\nThe answer should be in the form of a fraction.<eos><eos>\n\nThe number is in the form of a decimal point.\n\n<eos><eos><eos>\n\nThe number is in the form of a decimal point.<eos>\n\nThe number is in the form of a fraction.<eos><eos>\n\nThe number is in the form of a fraction.<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n\n<eos>\n\nThe number is in the form of a fraction.<eos>\n\nThe number is in the form of a fraction.<eos><eos><eos>\n\nThe number is in the form of a decimal.<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n\nThe number is in the form of a decimal.<eos><eos><eos><eos><eos>\n\nThe number is in the form of a fraction.<eos><eos><eos><eos><eos><eos>\n\nThe number is in the form of a decimal.<eos>\n\n<eos>\n\n<eos><eos><eos>\n\n<eos>\n\nThe number is in the form of a fraction.\n\n<eos><eos><eos>\n\nThe number is in the form of a fraction.<eos><eos><eos>\n\nThe number is in the form of a fraction.\n\nThe number is in the form of a fraction.<eos><eos><eos><eos>\n\nThe number is in the form of a fraction.<eos>\n\n<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n\nThe number is in the form of a fraction.<eos><eos>\n\nThe number is in the form of a fraction.<eos><eos><eos>\n\nThe number is in the form of a fraction.<eos><eos><eos>\n\nThe number is in the form of a fraction.<eos>\n\nThe number is in the form of a fraction.<eos><eos><eos>\n\nThe number is in the form of a fraction.<eos>\n\nThe number is in the form of a fraction.\n\nThe number is in the form of a fraction.<eos><eos>\n\nThe number is in the form of a fraction.<eos><eos><eos><eos>\n\nThe number is in the form of a fraction.\n\n<eos>\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.71s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 91 | Iter: 1 | Loss -0.0137939453125\nStep: 91 | Iter: 2 | Loss -0.0137939453125\nStep: 91 | Iter: 3 | Loss -0.0137939453125\nStep: 91 | Iter: 4 | Loss -0.0137939453125\nStep: 91 | Iter: 5 | Loss -0.0137939453125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.59s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 92 | Iter: 1 | Loss -0.01251220703125\nStep: 92 | Iter: 2 | Loss -0.01251220703125\nStep: 92 | Iter: 3 | Loss -0.01251220703125\nStep: 92 | Iter: 4 | Loss -0.01251220703125\nStep: 92 | Iter: 5 | Loss -0.01251220703125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.69s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 93 | Iter: 1 | Loss -0.0113525390625\nStep: 93 | Iter: 2 | Loss -0.0113525390625\nStep: 93 | Iter: 3 | Loss -0.01129150390625\nStep: 93 | Iter: 4 | Loss -0.0113525390625\nStep: 93 | Iter: 5 | Loss -0.0113525390625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.79s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 94 | Iter: 1 | Loss -0.0145263671875\nStep: 94 | Iter: 2 | Loss -0.0146484375\nStep: 94 | Iter: 3 | Loss -0.0145263671875\nStep: 94 | Iter: 4 | Loss -0.0145263671875\nStep: 94 | Iter: 5 | Loss -0.0146484375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.76s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 95 | Iter: 1 | Loss -0.0155029296875\nStep: 95 | Iter: 2 | Loss -0.0155029296875\nStep: 95 | Iter: 3 | Loss -0.0155029296875\nStep: 95 | Iter: 4 | Loss -0.0155029296875\nStep: 95 | Iter: 5 | Loss -0.0155029296875\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 96 | Iter: 1 | Loss nan\nStep: 96 | Iter: 2 | Loss nan\nStep: 96 | Iter: 3 | Loss nan\nStep: 96 | Iter: 4 | Loss nan\nStep: 96 | Iter: 5 | Loss nan\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.65s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 97 | Iter: 1 | Loss -0.01287841796875\nStep: 97 | Iter: 2 | Loss -0.01287841796875\nStep: 97 | Iter: 3 | Loss -0.01287841796875\nStep: 97 | Iter: 4 | Loss -0.01287841796875\nStep: 97 | Iter: 5 | Loss -0.01287841796875\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.66s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 98 | Iter: 1 | Loss nan\nStep: 98 | Iter: 2 | Loss nan\nStep: 98 | Iter: 3 | Loss nan\nStep: 98 | Iter: 4 | Loss nan\nStep: 98 | Iter: 5 | Loss nan\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.60s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 99 | Iter: 1 | Loss -0.01068115234375\nStep: 99 | Iter: 2 | Loss -0.01068115234375\nStep: 99 | Iter: 3 | Loss -0.01068115234375\nStep: 99 | Iter: 4 | Loss -0.01068115234375\nStep: 99 | Iter: 5 | Loss -0.01068115234375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.82s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 100 | Iter: 1 | Loss -0.01202392578125\nStep: 100 | Iter: 2 | Loss -0.01202392578125\nStep: 100 | Iter: 3 | Loss -0.01202392578125\nStep: 100 | Iter: 4 | Loss -0.01202392578125\nStep: 100 | Iter: 5 | Loss -0.01202392578125\nStep: 100 | Format: 0.001 | Accuracy: 0.004\nOutput example: <eos><eos><eos><eos><eos><eos><eos><eos> fin<eos><eos><eos><eos><eos> fin<eos><eos><eos><eos> fin\n\n<h3>More about the Art</h3><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n\n<h3>Comments</h3><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n<eos><eos>\n<eos>\n<eos><eos><eos>\n<eos><eos>\n<eos><eos><eos><eos><eos><eos><eos><eos><eos>\n<eos><eos><eos><eos><eos><eos><eos>\n<eos>\n<eos><eos><eos><eos><eos>\n<eos>\n?<eos><eos><eos><eos><eos><eos><eos><eos>\n?\n?<eos><eos><eos><eos><eos><eos><eos><eos>\n?<eos><eos><eos><eos>\n?\n?\n?\n?<eos>\n?<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n?\n?<eos>\n?<eos><eos><eos><eos>\n?<eos>\n?\n?\n?<eos><eos>\n?\n?<eos>\n?<eos>\n?<eos><eos><eos>\n?\n?<eos><eos><eos><eos>\n?<eos>\n?\n?\n?\n?<eos><eos><eos>\n?\n?\n?<eos><eos><eos><eos><eos><eos>\n?\n?\n?<eos><eos><eos><eos><eos><eos>\n?\n?\n?<eos><eos>\n?\n?\n?\n?\n?\n?<eos><eos><eos><eos><eos><eos><eos><eos>\n?\n?\n?\n?<eos><eos><eos><eos><eos><eos>\n?\n?<eos>\n?<eos><eos><eos><eos><eos><eos><eos>\n?<eos>\n?\n?\n?\n?\n?<eos><eos>\n?<eos><eos><eos><eos><eos>\n?<eos><eos><eos><eos><eos><eos><eos>\n?<eos><eos><eos><eos><eos><eos><eos><eos><eos>\n?\n?\n?<eos><eos><eos><eos><eos><eos>\n?<eos><eos>\n?<eos>\n?\n?<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n?\n?\n?<eos><eos><eos><eos><eos><eos><eos>\n?\n?\n?<eos><eos><eos><eos>\n?\n?<eos><eos><eos><eos><eos><eos><eos><eos>\n?<eos><eos><eos><eos><eos>\n?<eos><eos><eos>\n?\n?\n?\n?<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n?<eos><eos><eos><eos><eos>\n?<eos><eos><eos><eos>\n?\n?\n?\n?\n?<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n?<eos><eos><eos><eos>\n?<eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos><eos>\n?\n?<eos><eos><eos><eos><eos><eos><eos>\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.57s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 101 | Iter: 1 | Loss nan\nStep: 101 | Iter: 2 | Loss nan\nStep: 101 | Iter: 3 | Loss nan\nStep: 101 | Iter: 4 | Loss nan\nStep: 101 | Iter: 5 | Loss nan\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.68s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 102 | Iter: 1 | Loss nan\nStep: 102 | Iter: 2 | Loss nan\nStep: 102 | Iter: 3 | Loss nan\nStep: 102 | Iter: 4 | Loss nan\nStep: 102 | Iter: 5 | Loss nan\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.67s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 103 | Iter: 1 | Loss -0.01287841796875\nStep: 103 | Iter: 2 | Loss -0.01300048828125\nStep: 103 | Iter: 3 | Loss -0.01300048828125\nStep: 103 | Iter: 4 | Loss -0.01287841796875\nStep: 103 | Iter: 5 | Loss -0.01300048828125\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:29<00:00, 29.65s/it]\n","output_type":"stream"},{"name":"stdout","text":"Step: 104 | Iter: 1 | Loss nan\nStep: 104 | Iter: 2 | Loss nan\nStep: 104 | Iter: 3 | Loss nan\nStep: 104 | Iter: 4 | Loss nan\nStep: 104 | Iter: 5 | Loss nan\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/1 [00:10<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/4081766673.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         prompt_completions = generate_completions(\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/302872354.py\u001b[0m in \u001b[0;36mgenerate_completions\u001b[0;34m(model, tokenizer, prompts, temperature, num_completions, max_completion_length)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Generate completions using the current policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             outs = model.generate(\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             )\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1873\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1876\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2596\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2597\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2598\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2599\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3558\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3560\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3562\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma3/modeling_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    865\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma3/modeling_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    652\u001b[0m                 )\n\u001b[1;32m    653\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    655\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0mposition_embeddings_global\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_embeddings_global\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma3/modeling_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings_global, position_embeddings_local, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposition_embeddings_global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         hidden_states, self_attn_weights = self.self_attn(\n\u001b[0m\u001b[1;32m    464\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma3/modeling_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;34m\"sliding_window\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msliding_window\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             }\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mkey_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# Here we need to slice as we use a static cache by default, but FA2 does not support it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/cache_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, key_states, value_states, layer_idx, cache_kwargs)\u001b[0m\n\u001b[1;32m   1812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_sliding_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m             return _sliding_cache_update(\n\u001b[0m\u001b[1;32m   1815\u001b[0m                 \u001b[0mk_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m                 \u001b[0mv_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/cache_utils.py\u001b[0m in \u001b[0;36m_sliding_cache_update\u001b[0;34m(k_cache, v_cache, key_states, value_states, cache_position, max_cache_len)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# Clamp cache_position to determine the *target index* within the shifted cache view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mupdate_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_cache_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":23},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"code","source":"math_problem = SYSTEM + \"\"\"User: A farmer is planning to build a rectangular chicken coop using 100 meters of fencing.  \nOne side of the coop will be against a barn, so fencing is only needed for the other three sides.  \nWhat dimensions should the farmer choose to maximize the enclosed area?  \nProvide the maximum possible area in square meters.\nAssistant:\"\"\"  \n\nanswer = '1250'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T06:15:59.029912Z","iopub.status.idle":"2025-08-15T06:15:59.030213Z","shell.execute_reply.started":"2025-08-15T06:15:59.030092Z","shell.execute_reply":"2025-08-15T06:15:59.030104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generated_solution = model.generate(\n    **tokenizer(math_problem, return_tensors='pt').to('cuda'), \n    max_new_tokens=512,\n    pad_token_id=tokenizer.eos_token_id\n)\n\nprint('This is output from trained reasoning model!')\n\nprint(\n    tokenizer.decode(generated_solution[0]).split('Assistant:')[-1].strip()\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T06:15:59.031094Z","iopub.status.idle":"2025-08-15T06:15:59.031355Z","shell.execute_reply.started":"2025-08-15T06:15:59.031233Z","shell.execute_reply":"2025-08-15T06:15:59.031245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"baseline_solution = ref_model.generate(\n    **tokenizer(math_problem, return_tensors='pt').to('cuda'), \n    max_new_tokens=512,\n    temperature=0.6,\n    pad_token_id=tokenizer.eos_token_id\n)\n\nprint('This is output from base model!')\n\nprint(\n    tokenizer.decode(baseline_solution[0]).split('Assistant:')[-1].strip()\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T06:15:59.033125Z","iopub.status.idle":"2025-08-15T06:15:59.033835Z","shell.execute_reply.started":"2025-08-15T06:15:59.033644Z","shell.execute_reply":"2025-08-15T06:15:59.033668Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Plotting","metadata":{}},{"cell_type":"code","source":"def moving_average(data, window_size):\n    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T06:15:59.035428Z","iopub.status.idle":"2025-08-15T06:15:59.035715Z","shell.execute_reply.started":"2025-08-15T06:15:59.035584Z","shell.execute_reply":"2025-08-15T06:15:59.035596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(moving_average(track_format_rewards, window_size=100))\nplt.title(\"Format rewards\")\nplt.xlabel(\"Steps\")\nplt.ylabel(\"Reward\")\nplt.show()\n\n###########\nplt.plot(moving_average(track_accuracy_rewards, window_size=100))\nplt.title(\"Accuracy rewards\")\nplt.xlabel(\"Steps\")\nplt.ylabel(\"Reward\")\nplt.show()\n\n###########\nplt.plot(moving_average(total_rewards, window_size=100))\nplt.title(\"Total rewards\")\nplt.xlabel(\"Steps\")\nplt.ylabel(\"Reward\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T06:15:59.036689Z","iopub.status.idle":"2025-08-15T06:15:59.036923Z","shell.execute_reply.started":"2025-08-15T06:15:59.036814Z","shell.execute_reply":"2025-08-15T06:15:59.036825Z"}},"outputs":[],"execution_count":null}]}